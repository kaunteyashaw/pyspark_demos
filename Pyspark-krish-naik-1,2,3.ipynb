{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c93a9170",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyspark in c:\\users\\kaunteya\\anaconda3\\lib\\site-packages (3.2.1)\n",
      "Requirement already satisfied: py4j==0.10.9.3 in c:\\users\\kaunteya\\anaconda3\\lib\\site-packages (from pyspark) (0.10.9.3)\n"
     ]
    }
   ],
   "source": [
    "!pip install pyspark\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "160953d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pillow in c:\\users\\kaunteya\\anaconda3\\lib\\site-packages (8.4.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install pillow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0862b32e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1ab8f067",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "24208668",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\KAUNTEYA\n"
     ]
    }
   ],
   "source": [
    "import sys, os\n",
    "cwd = os.getcwd()\n",
    "print(cwd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e37fbe08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>krish</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sudhanshu</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>kaunteya</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>amrita</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        name  age\n",
       "0     krish    31\n",
       "1  sudhanshu   30\n",
       "2   kaunteya   24\n",
       "3     amrita   25"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"C:/Users/KAUNTEYA/test-pyspark.csv\")\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0d15a48f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "16b7b3d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName('Practice1') \\\n",
    "                    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d67444de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://lenovokspc:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.2.1</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>Practice1</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x1cf6c9f0580>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "44a36eae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----+------+------+---+------+----+\n",
      "|total_bill| tip|   sex|smoker|day|  time|size|\n",
      "+----------+----+------+------+---+------+----+\n",
      "|     16.99|1.01|Female|    No|Sun|Dinner|   2|\n",
      "|     10.34|1.66|  Male|    No|Sun|Dinner|   3|\n",
      "|     21.01| 3.5|  Male|    No|Sun|Dinner|   3|\n",
      "|     23.68|3.31|  Male|    No|Sun|Dinner|   2|\n",
      "|     24.59|3.61|Female|    No|Sun|Dinner|   4|\n",
      "|     25.29|4.71|  Male|    No|Sun|Dinner|   4|\n",
      "|      8.77|   2|  Male|    No|Sun|Dinner|   2|\n",
      "|     26.88|3.12|  Male|    No|Sun|Dinner|   4|\n",
      "|     15.04|1.96|  Male|    No|Sun|Dinner|   2|\n",
      "|     14.78|3.23|  Male|    No|Sun|Dinner|   2|\n",
      "|     10.27|1.71|  Male|    No|Sun|Dinner|   2|\n",
      "|     35.26|   5|Female|    No|Sun|Dinner|   4|\n",
      "|     15.42|1.57|  Male|    No|Sun|Dinner|   2|\n",
      "|     18.43|   3|  Male|    No|Sun|Dinner|   4|\n",
      "|     14.83|3.02|Female|    No|Sun|Dinner|   2|\n",
      "|     21.58|3.92|  Male|    No|Sun|Dinner|   2|\n",
      "|     10.33|1.67|Female|    No|Sun|Dinner|   3|\n",
      "|     16.29|3.71|  Male|    No|Sun|Dinner|   3|\n",
      "|     16.97| 3.5|Female|    No|Sun|Dinner|   3|\n",
      "|     20.65|3.35|  Male|    No|Sat|Dinner|   3|\n",
      "+----------+----+------+------+---+------+----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark1 = spark.read.option(\"header\", \"true\").csv('tips.csv')\n",
    "df_pyspark1.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "892b60e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- total_bill: string (nullable = true)\n",
      " |-- tip: string (nullable = true)\n",
      " |-- sex: string (nullable = true)\n",
      " |-- smoker: string (nullable = true)\n",
      " |-- day: string (nullable = true)\n",
      " |-- time: string (nullable = true)\n",
      " |-- size: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark1.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eb3606e",
   "metadata": {},
   "source": [
    "\n",
    "## Tutorial 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7f600697",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0c1948cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder \\\n",
    "        .appName(\"DataFramePractise1\") \\\n",
    "        .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "fbccd9ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://lenovokspc:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.2.1</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>Practice1</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x1cf6c9f0580>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "6786ddff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---+---+\n",
      "|     name|age|exp|\n",
      "+---------+---+---+\n",
      "|   krish | 31| 10|\n",
      "|sudhanshu| 30|  9|\n",
      "| kaunteya| 24|  3|\n",
      "|   amrita| 25|  1|\n",
      "+---------+---+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Read the dataset \n",
    "# one by read\n",
    "# one by \n",
    "\n",
    "df_pyspark = spark.read.option(\"header\", \"True\") \\\n",
    "            .csv('test1.csv', inferSchema=True)\n",
    "\n",
    "# output will be : DataFrame[name: string, age: string, exp: string]\n",
    "\n",
    "df_pyspark.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "154f3ebf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- name: string (nullable = true)\n",
      " |-- age: integer (nullable = true)\n",
      " |-- exp: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "6167af54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---+---+\n",
      "|     name|age|exp|\n",
      "+---------+---+---+\n",
      "|   krish | 31| 10|\n",
      "|sudhanshu| 30|  9|\n",
      "| kaunteya| 24|  3|\n",
      "|   amrita| 25|  1|\n",
      "+---------+---+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark = spark.read.csv('test1.csv', header=True, inferSchema=True)\n",
    "df_pyspark.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "dde94475",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.sql.dataframe.DataFrame"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(df_pyspark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "8f151c35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# selecting columsn and indexing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "fa8bbe86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['name', 'age', 'exp']"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pyspark.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "5d6a3d5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(name='krish ', age=31, exp=10),\n",
       " Row(name='sudhanshu', age=30, exp=9),\n",
       " Row(name='kaunteya', age=24, exp=3)]"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pyspark.head(3) # we will get result in list format, in pandas we get it dataframe format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "ef8b0dea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# how do we pick up a columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "3897e5a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---+---+\n",
      "|     name|age|exp|\n",
      "+---------+---+---+\n",
      "|   krish | 31| 10|\n",
      "|sudhanshu| 30|  9|\n",
      "| kaunteya| 24|  3|\n",
      "|   amrita| 25|  1|\n",
      "+---------+---+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "b06e6c8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---+\n",
      "|     name|age|\n",
      "+---------+---+\n",
      "|   krish | 31|\n",
      "|sudhanshu| 30|\n",
      "| kaunteya| 24|\n",
      "|   amrita| 25|\n",
      "+---------+---+\n",
      "\n",
      "+---------+---+\n",
      "|     name|age|\n",
      "+---------+---+\n",
      "|   krish | 31|\n",
      "|sudhanshu| 30|\n",
      "| kaunteya| 24|\n",
      "|   amrita| 25|\n",
      "+---------+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.select(['name', 'age']).show()\n",
    "\n",
    "# or\n",
    "df_pyspark.select('name', 'age').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "7d0257b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Column<'name'>"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pyspark['name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "cf84ee5c",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'Column' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_2640/516178908.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdf_pyspark\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'name'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: 'Column' object is not callable"
     ]
    }
   ],
   "source": [
    "df_pyspark['name'].show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "db49d772",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('name', 'string'), ('age', 'int'), ('exp', 'int')]"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " df_pyspark.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "30705657",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[summary: string, name: string, age: string, exp: string]"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pyspark.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "d6fcecae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---------+------------------+-----------------+\n",
      "|summary|     name|               age|              exp|\n",
      "+-------+---------+------------------+-----------------+\n",
      "|  count|        4|                 4|                4|\n",
      "|   mean|     null|              27.5|             5.75|\n",
      "| stddev|     null|3.5118845842842465|4.425306015783918|\n",
      "|    min|   amrita|                24|                1|\n",
      "|    max|sudhanshu|                31|               10|\n",
      "+-------+---------+------------------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "3f59e77c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## adding columns and dropping columns in dataframe:: pyspark dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "8190b922",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[name: string, age: int, exp: int, exp after 2 yrs: int]"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pyspark.withColumn('exp after 2 yrs', df_pyspark['exp']+2) # this is not a inplace operation, we have to assign to df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "ecfd5b46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---+---+---------------+\n",
      "|     name|age|exp|exp after 2 yrs|\n",
      "+---------+---+---+---------------+\n",
      "|   krish | 31| 10|             12|\n",
      "|sudhanshu| 30|  9|             11|\n",
      "| kaunteya| 24|  3|              5|\n",
      "|   amrita| 25|  1|              3|\n",
      "+---------+---+---+---------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.withColumn('exp after 2 yrs', df_pyspark['exp']+2).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "3a18b419",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---+---+\n",
      "|     name|age|exp|\n",
      "+---------+---+---+\n",
      "|   krish | 31| 10|\n",
      "|sudhanshu| 30|  9|\n",
      "| kaunteya| 24|  3|\n",
      "|   amrita| 25|  1|\n",
      "+---------+---+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Dropping\n",
    "df_pyspark = df_pyspark.drop('exp after 2 yrs')\n",
    "df_pyspark.show()\n",
    "# not inplace ops, assign to variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "ee23f2cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "## renaming\n",
    "\n",
    "df_pyspark = df_pyspark.withColumnRenamed('name', 'newName')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "c8db6776",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---+---+\n",
      "|  newName|age|exp|\n",
      "+---------+---+---+\n",
      "|   krish | 31| 10|\n",
      "|sudhanshu| 30|  9|\n",
      "| kaunteya| 24|  3|\n",
      "|   amrita| 25|  1|\n",
      "+---------+---+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbb95528",
   "metadata": {},
   "source": [
    "## Part 3 :: filter operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "2e8c3db6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "saprk = SparkSession.builder.appName('Practice2').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "d94373b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----+----+------+\n",
      "|     name| age| exp|salary|\n",
      "+---------+----+----+------+\n",
      "|   krish |  31|  10| 30000|\n",
      "|sudhanshu|  30|   9| 35000|\n",
      "| kaunteya|  24|   3| 60000|\n",
      "|   amrita|  25|   1| 35000|\n",
      "|   mahesh|null|null| 40000|\n",
      "|     null|  34|  10| 38000|\n",
      "|     null|  34|null|  null|\n",
      "+---------+----+----+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df2 = spark.read.csv('test2.csv', header=True, inferSchema=True)\n",
    "df2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "62a4f856",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.sql.dataframe.DataFrame"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## drop\n",
    "type(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "d091be19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----+------+\n",
      "| age| exp|salary|\n",
      "+----+----+------+\n",
      "|  31|  10| 30000|\n",
      "|  30|   9| 35000|\n",
      "|  24|   3| 60000|\n",
      "|  25|   1| 35000|\n",
      "|null|null| 40000|\n",
      "|  34|  10| 38000|\n",
      "|  34|null|  null|\n",
      "+----+----+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df2.drop('name').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "f63f4d16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----+----+------+\n",
      "|     name| age| exp|salary|\n",
      "+---------+----+----+------+\n",
      "|   krish |  31|  10| 30000|\n",
      "|sudhanshu|  30|   9| 35000|\n",
      "| kaunteya|  24|   3| 60000|\n",
      "|   amrita|  25|   1| 35000|\n",
      "|   mahesh|null|null| 40000|\n",
      "|     null|  34|  10| 38000|\n",
      "|     null|  34|null|  null|\n",
      "+---------+----+----+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df2.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "b9f3ffb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----+----+------+\n",
      "|     name| age| exp|salary|\n",
      "+---------+----+----+------+\n",
      "|   krish |  31|  10| 30000|\n",
      "|sudhanshu|  30|   9| 35000|\n",
      "| kaunteya|  24|   3| 60000|\n",
      "|   amrita|  25|   1| 35000|\n",
      "|   mahesh|null|null| 40000|\n",
      "|     null|  34|  10| 38000|\n",
      "+---------+----+----+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df2.na.drop(how=\"all\", thresh=2).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "810c112f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----+----+------+\n",
      "|     name| age| exp|salary|\n",
      "+---------+----+----+------+\n",
      "|   krish |  31|  10| 30000|\n",
      "|sudhanshu|  30|   9| 35000|\n",
      "| kaunteya|  24|   3| 60000|\n",
      "|   amrita|  25|   1| 35000|\n",
      "|   mahesh|null|null| 40000|\n",
      "|     null|  34|  10| 38000|\n",
      "|     null|  34|null|  null|\n",
      "+---------+----+----+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df2.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "999fd061",
   "metadata": {},
   "outputs": [],
   "source": [
    "# subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "5d836d9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---+---+------+\n",
      "|     name|age|exp|salary|\n",
      "+---------+---+---+------+\n",
      "|   krish | 31| 10| 30000|\n",
      "|sudhanshu| 30|  9| 35000|\n",
      "| kaunteya| 24|  3| 60000|\n",
      "|   amrita| 25|  1| 35000|\n",
      "|     null| 34| 10| 38000|\n",
      "+---------+---+---+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df2.na.drop(how=\"all\", subset=['exp']).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "9aa5b090",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----+----+------+\n",
      "|     name| age| exp|salary|\n",
      "+---------+----+----+------+\n",
      "|   krish |  31|  10| 30000|\n",
      "|sudhanshu|  30|   9| 35000|\n",
      "| kaunteya|  24|   3| 60000|\n",
      "|   amrita|  25|   1| 35000|\n",
      "|   mahesh|null|null| 40000|\n",
      "|     null|  34|  10| 38000|\n",
      "|     null|  34|null|  null|\n",
      "+---------+----+----+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "8fe9b285",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----+----+------+\n",
      "|     name| age| exp|salary|\n",
      "+---------+----+----+------+\n",
      "|   krish |  31|  10| 30000|\n",
      "|sudhanshu|  30|   9| 35000|\n",
      "| kaunteya|  24|   3| 60000|\n",
      "|   amrita|  25|   1| 35000|\n",
      "|   mahesh|null|null| 40000|\n",
      "|     null|  34|  10| 38000|\n",
      "|     null|  34|null|  null|\n",
      "+---------+----+----+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df2 = df2.na.fill(\"N/A\", subset=['age']).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "48583c3a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af8f8fe1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
